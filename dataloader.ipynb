{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataloader.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8kAzeoFOvlCfhQ24Uc1eC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexHeyman/FewShotGANTraining/blob/main/dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__52Y9SRjUwH"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch==1.10.0 torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53DRDsUXjeBy",
        "outputId": "1970606f-eb3e-4f57-c388-f9c85237d5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvPBW4uwlY7P",
        "outputId": "d5e7864c-51d6-4f47-efc6-857407a39b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "from typing import Any, Dict\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import shutil\n",
        "import json"
      ],
      "metadata": {
        "id": "zNCnvLqCkaRS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_Generated_parameters(model):\n",
        "    flatten = deepcopy(list(p.data for p in model.parameters()))\n",
        "    return flatten"
      ],
      "metadata": {
        "id": "2ObeIBraPHD6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_parameters(model, new_parameter):\n",
        "    for p, new_param in zip(model.parameters(), new_parameter):\n",
        "        p.data.copy_(new_param)"
      ],
      "metadata": {
        "id": "-g5UNBoYPHOq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_directory(args):\n",
        "    folder_name = 'train_results/' + args.name\n",
        "    saved_model_folder = os.path.join( folder_name, 'models')\n",
        "    saved_image_folder = os.path.join( folder_name, 'images')\n",
        "    \n",
        "    os.makedirs(saved_model_folder, exist_ok=True)\n",
        "    os.makedirs(saved_image_folder, exist_ok=True)\n",
        "\n",
        "    for f in os.listdir('./'):\n",
        "        if '.py' in f:\n",
        "            shutil.copy(f, folder_name+'/'+f)\n",
        "    \n",
        "    with open( os.path.join(saved_model_folder, '../args.txt'), 'w') as f:\n",
        "        json.dump(args.__dict__, f, indent=2)\n",
        "\n",
        "    return saved_model_folder, saved_image_folder"
      ],
      "metadata": {
        "id": "X_HeTj-qPHbF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {\n",
        "    'url': '/content/gdrive/MyDrive/DATASETS/few-shot-image-datasets.zip',\n",
        "    'archive': 'few-shot-image-datasets.zip',\n",
        "    'destination': 'few-shot-image-datasets',\n",
        "}"
      ],
      "metadata": {
        "id": "eHeEU8a-kaqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_dataset(root: str,\n",
        "                    url: str,\n",
        "                    archive: str,\n",
        "                    destination: str):\n",
        "    destination_path = os.path.join(root, destination)\n",
        "    archive_path = os.path.join(root, archive)\n",
        "\n",
        "    if not os.path.isdir(destination_path):\n",
        "        urllib.request.urlretrieve(url, archive_path)\n",
        "\n",
        "        if archive_path.endswith('.zip'):\n",
        "            with zipfile.ZipFile(archive_path, 'r') as zip:\n",
        "                zip.extractall(root)"
      ],
      "metadata": {
        "id": "njg8enA0ka_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MergeFewShotImageDatasets:\n",
        "\n",
        "    def __init__(self, root: str):\n",
        "        extract_dataset(\n",
        "                root=root,\n",
        "                url=_dataset['url'],\n",
        "                archive=_dataset['archive'],\n",
        "                destination=_dataset['destination'],\n",
        "            )\n"
      ],
      "metadata": {
        "id": "dBV97peykbVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FewShotImageDataset(MergeFewShotImageDatasets, Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, root: str,\n",
        "                       subdirectory: str):\n",
        "        super().__init__(root)\n",
        "        self._root = os.path.join(root, subdirectory)\n",
        "        self._files = os.listdir(self._root)\n",
        "\n",
        "        self._transforms = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.Resize((1024, 1024)),\n",
        "                torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "            ])"
      ],
      "metadata": {
        "id": "Xabm-5TbkbtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _length_(self):\n",
        "        return len(self._files)"
      ],
      "metadata": {
        "id": "6lo5ngNOkcGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieveimage(self, index: int) -> Dict[str, Any]:\n",
        "        image_path = os.path.join(self._root, self._files[index])\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = torch.from_numpy(np.array(image))\n",
        "        image = image.permute(2, 0, 1)\n",
        "        image = self._transforms(image)\n",
        "        return {'image': image}"
      ],
      "metadata": {
        "id": "Vyp4TF_okcjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoiseDataset(Dataset):\n",
        "\n",
        "    def __init__(self, size: int, channels: int):\n",
        "        self._size = size\n",
        "        self._channels = channels\n",
        "\n",
        "    def _length_(self):\n",
        "        return self._size\n",
        "\n",
        "    def retrieveimage(self, index: int) -> torch.Tensor:\n",
        "        return torch.zeros(self._channels, 1, 1).normal_(0.0, 1.0)"
      ],
      "metadata": {
        "id": "hBAaT4rikcp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:https://github.com/silentz/Towards-Faster-And-Stabilized-GAN-Training-For-High-Fidelity-Few-Shot-Image-Synthesis\n"
      ],
      "metadata": {
        "id": "xyj3pNOAn87m"
      }
    }
  ]
}